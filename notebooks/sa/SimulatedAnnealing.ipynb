{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import random as rm\n",
    "\n",
    "# Add the sibling folders\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "import src.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # define all the components that will be used in the NN (these can be reused)\n",
    "        self.fc1 = nn.Linear(784,100, bias=False)\n",
    "        self.fc2 = nn.Linear(100,10, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define the acutal network\n",
    "        in_size = x.size(0) # get the batch size\n",
    "        \n",
    "        x = x.view(in_size, -1) # flatten data, -1 is inferred from the other dimensions\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # Provare aggiungendo softmax\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = ut.load_dataset(dataset_name='mnist', minibatch=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_minibatch(inputs, labels, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    outputs = model(Variable(inputs))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    test_loss += float(F.cross_entropy(outputs, Variable(labels)).item())\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, optimizer, criterion, update_number, gpu=True):\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        print(\"Prima:\", test_minibatch(inputs, labels, net))\n",
    "        for j in range(update_number):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        if i % 10 and 0 == 1:\n",
    "            '''for param in model.parameters():\n",
    "                print(param.grad.mul(0.01), param.grad.size())'''\n",
    "            print(test_minibatch(inputs, labels, net))\n",
    "            \n",
    "        print(\"Dopo:\", test_minibatch(inputs, labels, net))\n",
    "        del inputs, labels, outputs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "net = Net().cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    if epoch == 1:\n",
    "        print(\"Epoch pre: \", epoch)\n",
    "        print(ut.test(test_loader, net))\n",
    "    \n",
    "    train(train_loader, net, optimizer, criterion, 1)\n",
    "    print(\"Epoch: \", epoch, \"value:\", ut.test(test_loader, net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mail\n",
    "Una cosa che mi intriga è la seguente: noi sappiamo che, per f.o. L(w) differenziabili come quelli che stiamo considerando, esiste un gradiente \n",
    "\n",
    "$$ g(w) $$\n",
    "\n",
    "che potremmo (ma non vogliamo) calcolare. Dato il set w dei parametri correnti, noi generiamo una “mossa” random \\Delta(w) e valutiamo la f.o. L(w)  in \n",
    "\n",
    "$$ w' := w - \\epsilon \\Delta(w) $$\n",
    "\n",
    "per un piccolo \\epsilon > 0. Ora se la norma di \\epsilon \\Delta(w) è piccola noi sappiamo (approssimazione di Taylor) che \n",
    "\n",
    "$$ L(w’) ~= L(w) - \\epsilon g(w)^T \\Delta(w) $$\n",
    "\n",
    "quindi la f.o. migliora se  \n",
    "\n",
    "$$ g(w)^T \\Delta(w) > 0 $$\n",
    "\n",
    "(cioè se vettori -g(w) e \\Delta(w) formano un angolo acuto). Se questo non succede, allora potremmo eseguire lo spostamento nella direzione contraria\n",
    "\n",
    "$$\tw\" := w + \\epsilon \\Delta(w) $$ \n",
    "\n",
    "con la speranza di migliorare. \n",
    "\n",
    "In un’ottica Simulated Annealing, questo corrisponde a considerare come “mossa di base” (per un \\Delta(w) random) il migliore dei due spostamenti\n",
    "\n",
    "$$ w' := w - \\epsilon \\Delta(w) $$\n",
    "$$ w\" := w + \\epsilon \\Delta(w) $$\n",
    "\n",
    "Se il migliore dei due migliora L(w) allora accettiamo certamente la mossa, se no la accettiamo con una probabilità legata alla temperatura, ecc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maximum_percentage = 0.001\n",
    "net = Net()\n",
    "net.cuda()\n",
    "\n",
    "for epoch in range(3):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    net.train() # to check\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        if (i == 0):\n",
    "            accuracy_before = ut.test_train_sample(train_loader2, net, n_minibatches=4) # to improve\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        grad = None\n",
    "        grad2 = None\n",
    "        inverse = []\n",
    "        for k, param in enumerate(net.parameters()):  # Loop across each layer\n",
    "            size = param.data.size()\n",
    "            grad = param.data.clone()\n",
    "            grad2 = param.data.clone()\n",
    "            for i in range(size[0]):\n",
    "                for j in range(size[1]):\n",
    "                    grad.data[i][j] = rm.uniform(-1, 1) * maximum_percentage * param.data[i][j]\n",
    "                    grad2.data[i][j] = grad.data[i][j] * 2 * -1\n",
    "\n",
    "            #print(grad.data, grad.data.size())\n",
    "            #print(grad2.data, grad2.data.size()) \n",
    "            \n",
    "            inverse.append(grad2.data)\n",
    "            param.data.add_(grad.data)\n",
    "\n",
    "        new_accuracy = ut.test_train_sample(train_loader2, net, n_minibatches=4)\n",
    "        \n",
    "        print(\"New accuracy 1: \", new_accuracy)\n",
    "        if new_accuracy[1] < accuracy_before[1]:\n",
    "            for k, param in enumerate(net.parameters()):\n",
    "                param.data.add_(inverse[k])\n",
    "            new_accuracy = ut.test_train_sample(train_loader2, net, n_minibatches=4)\n",
    "            print(\"New accuracy (inverse):\", new_accuracy)\n",
    "        \n",
    "        accuracy_before = new_accuracy\n",
    "        \n",
    "        \n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(src.utils.test(test_loader, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Accuracy inizio epoca: (0.0005848147432009379, 0.13281666666666667)\n",
      "Direzione sbagliata infatti: 0.12443333333333334\n",
      "Accuracy fine epoca:  (0.0005837009827295939, 0.14145)\n",
      "Epoch:  1\n",
      "Accuracy inizio epoca: (0.0005837320526440938, 0.14145)\n",
      "Direzione sbagliata infatti: 0.13806666666666667\n",
      "Accuracy fine epoca:  (0.0005828081448872885, 0.14458333333333334)\n",
      "Epoch:  2\n",
      "Accuracy inizio epoca: (0.0005827558279037475, 0.14458333333333334)\n",
      "Accuracy fine epoca:  (0.000582395871480306, 0.14865)\n",
      "Epoch:  3\n",
      "Accuracy inizio epoca: (0.0005823869387308756, 0.14865)\n",
      "Direzione sbagliata infatti: 0.14725\n",
      "Accuracy fine epoca:  (0.0005820811271667481, 0.14846666666666666)\n",
      "Epoch:  4\n",
      "Accuracy inizio epoca: (0.0005820894559224447, 0.14846666666666666)\n",
      "Direzione sbagliata infatti: 0.13901666666666668\n",
      "Accuracy fine epoca:  (0.0005819591800371805, 0.15708333333333332)\n",
      "Epoch:  5\n",
      "Accuracy inizio epoca: (0.0005819628755251567, 0.15708333333333332)\n",
      "Direzione sbagliata infatti: 0.1545\n",
      "Accuracy fine epoca:  (0.0005821549495061239, 0.15941666666666668)\n",
      "Epoch:  6\n",
      "Accuracy inizio epoca: (0.0005821572621663412, 0.15941666666666668)\n",
      "Direzione sbagliata infatti: 0.15071666666666667\n",
      "Accuracy fine epoca:  (0.000582466435432434, 0.16593333333333332)\n",
      "Epoch:  7\n",
      "Accuracy inizio epoca: (0.0005824451645215352, 0.16593333333333332)\n",
      "Accuracy fine epoca:  (0.0005821534832318624, 0.16855)\n",
      "Epoch:  8\n",
      "Accuracy inizio epoca: (0.0005821393450101217, 0.16855)\n",
      "Direzione sbagliata infatti: 0.16345\n",
      "Accuracy fine epoca:  (0.0005819443861643473, 0.17156666666666667)\n",
      "Epoch:  9\n",
      "Accuracy inizio epoca: (0.0005818940679232279, 0.17156666666666667)\n",
      "Direzione sbagliata infatti: 0.16391666666666665\n",
      "Accuracy fine epoca:  (0.0005816428422927856, 0.17103333333333334)\n",
      "Epoch:  10\n",
      "Accuracy inizio epoca: (0.0005816379268964132, 0.17103333333333334)\n",
      "Accuracy fine epoca:  (0.0005801953434944152, 0.17823333333333333)\n",
      "Epoch:  11\n",
      "Accuracy inizio epoca: (0.000580146582921346, 0.17823333333333333)\n",
      "Direzione sbagliata infatti: 0.17411666666666667\n",
      "Accuracy fine epoca:  (0.0005801462610562642, 0.18016666666666667)\n",
      "Epoch:  12\n",
      "Accuracy inizio epoca: (0.0005801207820574442, 0.18016666666666667)\n",
      "Direzione sbagliata infatti: 0.17858333333333334\n",
      "Accuracy fine epoca:  (0.0005802888751029968, 0.18151666666666666)\n",
      "Epoch:  13\n",
      "Accuracy inizio epoca: (0.0005803467869758606, 0.18151666666666666)\n",
      "Accuracy fine epoca:  (0.0005798579414685567, 0.1818)\n",
      "Epoch:  14\n",
      "Accuracy inizio epoca: (0.0005797787586847941, 0.1818)\n",
      "Direzione sbagliata infatti: 0.17628333333333332\n",
      "Accuracy fine epoca:  (0.0005790372212727865, 0.18568333333333334)\n",
      "Epoch:  15\n",
      "Accuracy inizio epoca: (0.0005790791074434916, 0.18568333333333334)\n",
      "Accuracy fine epoca:  (0.0005790130615234375, 0.18865)\n",
      "Epoch:  16\n",
      "Accuracy inizio epoca: (0.000578934645652771, 0.18865)\n",
      "Direzione sbagliata infatti: 0.18516666666666667\n",
      "Accuracy fine epoca:  (0.0005787540396054586, 0.18986666666666666)\n",
      "Epoch:  17\n",
      "Accuracy inizio epoca: (0.0005787203470865885, 0.18986666666666666)\n",
      "Accuracy fine epoca:  (0.0005784266789754231, 0.19175)\n",
      "Epoch:  18\n",
      "Accuracy inizio epoca: (0.0005784291744232178, 0.19175)\n",
      "Direzione sbagliata infatti: 0.19103333333333333\n",
      "Accuracy fine epoca:  (0.0005780868252118429, 0.19123333333333334)\n",
      "Epoch:  19\n",
      "Accuracy inizio epoca: (0.0005781309485435486, 0.19123333333333334)\n",
      "Direzione sbagliata infatti: 0.18928333333333333\n",
      "Accuracy fine epoca:  (0.0005777647376060485, 0.19423333333333334)\n",
      "Epoch:  20\n",
      "Accuracy inizio epoca: (0.0005777178883552551, 0.19423333333333334)\n",
      "Direzione sbagliata infatti: 0.19138333333333332\n",
      "Accuracy fine epoca:  (0.0005780558784802755, 0.1954)\n",
      "Epoch:  21\n",
      "Accuracy inizio epoca: (0.0005781032721201578, 0.1954)\n",
      "Accuracy fine epoca:  (0.0005775997837384542, 0.19738333333333333)\n",
      "Epoch:  22\n",
      "Accuracy inizio epoca: (0.0005775094350179037, 0.19738333333333333)\n",
      "Accuracy fine epoca:  (0.0005774832646052042, 0.19765)\n",
      "Epoch:  23\n",
      "Accuracy inizio epoca: (0.0005775037010510763, 0.19765)\n",
      "Direzione sbagliata infatti: 0.19656666666666667\n",
      "Accuracy fine epoca:  (0.0005779242674509684, 0.19748333333333334)\n",
      "Epoch:  24\n",
      "Accuracy inizio epoca: (0.0005779131531715394, 0.19748333333333334)\n",
      "Direzione sbagliata infatti: 0.1959\n",
      "Accuracy fine epoca:  (0.0005785099069277445, 0.19873333333333335)\n",
      "Epoch:  25\n",
      "Accuracy inizio epoca: (0.0005784938454627991, 0.19873333333333335)\n",
      "Direzione sbagliata infatti: 0.19515\n",
      "Accuracy fine epoca:  (0.0005777973453203837, 0.20121666666666665)\n",
      "Epoch:  26\n",
      "Accuracy inizio epoca: (0.0005778555671374004, 0.20121666666666665)\n",
      "Accuracy fine epoca:  (0.0005768480817476908, 0.20238333333333333)\n",
      "Epoch:  27\n",
      "Accuracy inizio epoca: (0.0005767935434977214, 0.20238333333333333)\n",
      "Accuracy fine epoca:  (0.0005773561080296834, 0.20303333333333334)\n",
      "Epoch:  28\n",
      "Accuracy inizio epoca: (0.0005774328748385111, 0.20303333333333334)\n",
      "Direzione sbagliata infatti: 0.20098333333333335\n",
      "Accuracy fine epoca:  (0.0005764349738756816, 0.20293333333333333)\n",
      "Epoch:  29\n",
      "Accuracy inizio epoca: (0.0005764219323794047, 0.20293333333333333)\n",
      "Accuracy fine epoca:  (0.0005763503670692444, 0.20468333333333333)\n",
      "Epoch:  30\n",
      "Accuracy inizio epoca: (0.0005764074484507243, 0.20468333333333333)\n",
      "Accuracy fine epoca:  (0.0005757466514905294, 0.20595)\n",
      "Epoch:  31\n",
      "Accuracy inizio epoca: (0.0005757816433906556, 0.20595)\n",
      "Direzione sbagliata infatti: 0.20566666666666666\n",
      "Accuracy fine epoca:  (0.0005756558219591777, 0.2059)\n",
      "Epoch:  32\n",
      "Accuracy inizio epoca: (0.0005755885998408, 0.2059)\n",
      "Accuracy fine epoca:  (0.0005742001255353292, 0.20991666666666667)\n",
      "Epoch:  33\n",
      "Accuracy inizio epoca: (0.000574248989423116, 0.20991666666666667)\n",
      "Direzione sbagliata infatti: 0.20953333333333332\n",
      "Accuracy fine epoca:  (0.0005740065455436706, 0.2092)\n",
      "Epoch:  34\n",
      "Accuracy inizio epoca: (0.0005739955027898153, 0.2092)\n",
      "Accuracy fine epoca:  (0.000574322509765625, 0.2092)\n",
      "Epoch:  35\n",
      "Accuracy inizio epoca: (0.0005743098060290019, 0.2092)\n",
      "Direzione sbagliata infatti: 0.20496666666666666\n",
      "Accuracy fine epoca:  (0.000574075436592102, 0.21178333333333332)\n",
      "Epoch:  36\n",
      "Accuracy inizio epoca: (0.0005741119106610616, 0.21178333333333332)\n",
      "Direzione sbagliata infatti: 0.20961666666666667\n",
      "Accuracy fine epoca:  (0.0005750401059786479, 0.21381666666666665)\n",
      "Epoch:  37\n",
      "Accuracy inizio epoca: (0.0005750381946563721, 0.21381666666666665)\n",
      "Direzione sbagliata infatti: 0.21311666666666668\n",
      "Accuracy fine epoca:  (0.0005755801796913147, 0.2116)\n",
      "Epoch:  38\n",
      "Accuracy inizio epoca: (0.0005755762378374735, 0.2116)\n",
      "Direzione sbagliata infatti: 0.2098\n",
      "Accuracy fine epoca:  (0.0005751404762268066, 0.21238333333333334)\n",
      "Epoch:  39\n",
      "Accuracy inizio epoca: (0.0005751884778340657, 0.21238333333333334)\n",
      "Accuracy fine epoca:  (0.0005755902727444966, 0.2129)\n",
      "Epoch:  40\n",
      "Accuracy inizio epoca: (0.0005754921356836954, 0.2129)\n",
      "Direzione sbagliata infatti: 0.20828333333333332\n",
      "Accuracy fine epoca:  (0.0005751428524653117, 0.21601666666666666)\n",
      "Epoch:  41\n",
      "Accuracy inizio epoca: (0.0005752490401268005, 0.21601666666666666)\n",
      "Direzione sbagliata infatti: 0.21268333333333334\n",
      "Accuracy fine epoca:  (0.0005748698711395264, 0.2185)\n",
      "Epoch:  42\n",
      "Accuracy inizio epoca: (0.0005748431364695231, 0.2185)\n",
      "Direzione sbagliata infatti: 0.21673333333333333\n",
      "Accuracy fine epoca:  (0.0005761477470397949, 0.21881666666666666)\n",
      "Epoch:  43\n",
      "Accuracy inizio epoca: (0.0005761016368865967, 0.21881666666666666)\n",
      "Direzione sbagliata infatti: 0.21436666666666668\n",
      "Accuracy fine epoca:  (0.0005758455673853557, 0.22133333333333333)\n",
      "Epoch:  44\n",
      "Accuracy inizio epoca: (0.0005758406360944112, 0.22133333333333333)\n",
      "Accuracy fine epoca:  (0.0005758840521176656, 0.22355)\n",
      "Epoch:  45\n",
      "Accuracy inizio epoca: (0.0005758173227310181, 0.22355)\n",
      "Accuracy fine epoca:  (0.0005752752820650736, 0.22558333333333333)\n",
      "Epoch:  46\n",
      "Accuracy inizio epoca: (0.0005752848108609518, 0.22558333333333333)\n",
      "Direzione sbagliata infatti: 0.22413333333333332\n",
      "Accuracy fine epoca:  (0.0005751156528790792, 0.22401666666666667)\n",
      "Epoch:  47\n",
      "Accuracy inizio epoca: (0.0005751434564590454, 0.22401666666666667)\n",
      "Direzione sbagliata infatti: 0.21715\n",
      "Accuracy fine epoca:  (0.000574862011273702, 0.22768333333333332)\n",
      "Epoch:  48\n",
      "Accuracy inizio epoca: (0.0005749226172765096, 0.22768333333333332)\n",
      "Accuracy fine epoca:  (0.0005746983329455058, 0.22838333333333333)\n",
      "Epoch:  49\n",
      "Accuracy inizio epoca: (0.0005746374011039734, 0.22838333333333333)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direzione sbagliata infatti: 0.22775\n",
      "Accuracy fine epoca:  (0.0005741359273592631, 0.22743333333333332)\n",
      "Epoch:  50\n",
      "Accuracy inizio epoca: (0.0005740385452906291, 0.22743333333333332)\n",
      "Direzione sbagliata infatti: 0.22563333333333332\n",
      "Accuracy fine epoca:  (0.0005733922799428304, 0.22838333333333333)\n",
      "Epoch:  51\n",
      "Accuracy inizio epoca: (0.0005734728495279948, 0.22838333333333333)\n",
      "Accuracy fine epoca:  (0.000573296594619751, 0.2305)\n",
      "Epoch:  52\n",
      "Accuracy inizio epoca: (0.0005732896645863851, 0.2305)\n",
      "Direzione sbagliata infatti: 0.22916666666666666\n",
      "Accuracy fine epoca:  (0.0005732404788335165, 0.2299)\n",
      "Epoch:  53\n",
      "Accuracy inizio epoca: (0.000573265814781189, 0.2299)\n",
      "Direzione sbagliata infatti: 0.22055\n",
      "Accuracy fine epoca:  (0.0005717859586079915, 0.23791666666666667)\n",
      "Epoch:  54\n",
      "Accuracy inizio epoca: (0.0005717929085095724, 0.23791666666666667)\n",
      "Direzione sbagliata infatti: 0.2342\n",
      "Accuracy fine epoca:  (0.0005713620702425639, 0.24016666666666667)\n",
      "Epoch:  55\n",
      "Accuracy inizio epoca: (0.0005713422338167826, 0.24016666666666667)\n",
      "Direzione sbagliata infatti: 0.23885\n",
      "Accuracy fine epoca:  (0.0005702149391174316, 0.23968333333333333)\n",
      "Epoch:  56\n",
      "Accuracy inizio epoca: (0.0005702276150385539, 0.23968333333333333)\n",
      "Accuracy fine epoca:  (0.0005696868141492208, 0.24346666666666666)\n",
      "Epoch:  57\n",
      "Accuracy inizio epoca: (0.000569663671652476, 0.24346666666666666)\n",
      "Accuracy fine epoca:  (0.0005691411892573038, 0.2451)\n",
      "Epoch:  58\n",
      "Accuracy inizio epoca: (0.0005690371433893839, 0.2451)\n",
      "Direzione sbagliata infatti: 0.24463333333333334\n",
      "Accuracy fine epoca:  (0.0005691612601280212, 0.24223333333333333)\n",
      "Epoch:  59\n",
      "Accuracy inizio epoca: (0.0005691531777381897, 0.24223333333333333)\n",
      "Accuracy fine epoca:  (0.000568480122089386, 0.24241666666666667)\n",
      "Epoch:  60\n",
      "Accuracy inizio epoca: (0.0005684725324312846, 0.24241666666666667)\n",
      "Accuracy fine epoca:  (0.0005675682942072551, 0.24423333333333333)\n",
      "Epoch:  61\n",
      "Accuracy inizio epoca: (0.0005676465431849162, 0.24423333333333333)\n",
      "Direzione sbagliata infatti: 0.24405\n",
      "Accuracy fine epoca:  (0.000567253045241038, 0.24383333333333335)\n",
      "Epoch:  62\n",
      "Accuracy inizio epoca: (0.0005671626130739848, 0.24383333333333335)\n",
      "Accuracy fine epoca:  (0.0005663209597269694, 0.2472)\n",
      "Epoch:  63\n",
      "Accuracy inizio epoca: (0.0005663007418314615, 0.2472)\n",
      "Direzione sbagliata infatti: 0.24446666666666667\n",
      "Accuracy fine epoca:  (0.0005666945060094198, 0.24681666666666666)\n",
      "Epoch:  64\n",
      "Accuracy inizio epoca: (0.0005668064991633097, 0.24681666666666666)\n",
      "Accuracy fine epoca:  (0.000567216976483663, 0.2539166666666667)\n",
      "Epoch:  65\n",
      "Accuracy inizio epoca: (0.0005671774903933208, 0.2539166666666667)\n",
      "Direzione sbagliata infatti: 0.24916666666666668\n",
      "Accuracy fine epoca:  (0.0005667879025141398, 0.25765)\n",
      "Epoch:  66\n",
      "Accuracy inizio epoca: (0.000566847542921702, 0.25765)\n",
      "Accuracy fine epoca:  (0.0005669265468915304, 0.26163333333333333)\n",
      "Epoch:  67\n",
      "Accuracy inizio epoca: (0.0005668434898058574, 0.26163333333333333)\n",
      "Direzione sbagliata infatti: 0.25505\n",
      "Accuracy fine epoca:  (0.0005662775913874308, 0.26655)\n",
      "Epoch:  68\n",
      "Accuracy inizio epoca: (0.000566275680065155, 0.26655)\n",
      "Accuracy fine epoca:  (0.0005655634125073751, 0.2705)\n",
      "Epoch:  69\n",
      "Accuracy inizio epoca: (0.0005655112743377685, 0.2705)\n",
      "Accuracy fine epoca:  (0.0005651507536570231, 0.2716)\n",
      "Epoch:  70\n",
      "Accuracy inizio epoca: (0.0005651685873667399, 0.2716)\n",
      "Accuracy fine epoca:  (0.0005659736831982931, 0.27216666666666667)\n",
      "Epoch:  71\n",
      "Accuracy inizio epoca: (0.0005658950130144755, 0.27216666666666667)\n",
      "Direzione sbagliata infatti: 0.27053333333333335\n",
      "Accuracy fine epoca:  (0.000565271782875061, 0.2720666666666667)\n",
      "Epoch:  72\n",
      "Accuracy inizio epoca: (0.0005652422706286113, 0.2720666666666667)\n",
      "Direzione sbagliata infatti: 0.2681\n",
      "Accuracy fine epoca:  (0.0005650022308031718, 0.27316666666666667)\n",
      "Epoch:  73\n",
      "Accuracy inizio epoca: (0.0005649911324183146, 0.27316666666666667)\n",
      "Accuracy fine epoca:  (0.0005644372979799906, 0.2748)\n",
      "Epoch:  74\n",
      "Accuracy inizio epoca: (0.0005644428928693136, 0.2748)\n",
      "Direzione sbagliata infatti: 0.2712333333333333\n",
      "Accuracy fine epoca:  (0.00056432576974233, 0.27581666666666665)\n",
      "Epoch:  75\n",
      "Accuracy inizio epoca: (0.0005642763376235962, 0.27581666666666665)\n",
      "Direzione sbagliata infatti: 0.27518333333333334\n",
      "Accuracy fine epoca:  (0.0005627229531606038, 0.27243333333333336)\n",
      "Epoch:  76\n",
      "Accuracy inizio epoca: (0.0005626499811808268, 0.27243333333333336)\n",
      "Direzione sbagliata infatti: 0.2652\n",
      "Accuracy fine epoca:  (0.0005622428456942241, 0.2792)\n",
      "Epoch:  77\n",
      "Accuracy inizio epoca: (0.0005622341990470886, 0.2792)\n",
      "Accuracy fine epoca:  (0.0005612066189448039, 0.2865333333333333)\n",
      "Epoch:  78\n",
      "Accuracy inizio epoca: (0.0005612308661142985, 0.2865333333333333)\n",
      "Direzione sbagliata infatti: 0.2796\n",
      "Accuracy fine epoca:  (0.000559148661295573, 0.29181666666666667)\n",
      "Epoch:  79\n",
      "Accuracy inizio epoca: (0.0005592181205749512, 0.29181666666666667)\n",
      "Direzione sbagliata infatti: 0.2860333333333333\n",
      "Accuracy fine epoca:  (0.0005587501446406046, 0.2920333333333333)\n",
      "Epoch:  80\n",
      "Accuracy inizio epoca: (0.0005587366422017415, 0.2920333333333333)\n",
      "Accuracy fine epoca:  (0.0005588939746220907, 0.2935833333333333)\n",
      "Epoch:  81\n",
      "Accuracy inizio epoca: (0.0005588552355766296, 0.2935833333333333)\n",
      "Direzione sbagliata infatti: 0.29065\n",
      "Accuracy fine epoca:  (0.0005583001852035522, 0.2950333333333333)\n",
      "Epoch:  82\n",
      "Accuracy inizio epoca: (0.0005582767923672994, 0.2950333333333333)\n",
      "Accuracy fine epoca:  (0.0005584943095842997, 0.29668333333333335)\n",
      "Epoch:  83\n",
      "Accuracy inizio epoca: (0.0005584371924400329, 0.29668333333333335)\n",
      "Accuracy fine epoca:  (0.0005582247138023376, 0.2989)\n",
      "Epoch:  84\n",
      "Accuracy inizio epoca: (0.0005582172513008117, 0.2989)\n",
      "Direzione sbagliata infatti: 0.297\n"
     ]
    }
   ],
   "source": [
    "maximum_percentage = 10e-1 / 2\n",
    "net = Net().cuda()\n",
    "train_loader, test_loader = ut.load_dataset(dataset_name='mnist', minibatch=4096)\n",
    "\n",
    "def train_SA(trainloader, model, gpu=True):\n",
    "    model.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        if i == 0:\n",
    "            accuracy_before = test_minibatch(inputs, labels, net)\n",
    "        \n",
    "        grad = None\n",
    "        grad2 = None\n",
    "        inverse = []\n",
    "        \n",
    "        for param in net.parameters():\n",
    "            size = param.data.size()\n",
    "            grad = param.data.clone()\n",
    "            grad2 = param.data.clone()\n",
    "            \n",
    "            for i in range(size[0]):\n",
    "                for j in range(size[1]):\n",
    "                    grad.data[i][j] = rm.uniform(-1, 1) * maximum_percentage * param.data[i][j]\n",
    "                    grad2.data[i][j] = grad.data[i][j] * 2 * -1\n",
    "            #print(grad.data)\n",
    "            inverse.append(grad2.data)\n",
    "            param.data.add_(grad.data)\n",
    "        \n",
    "        new_accuracy = test_minibatch(inputs, labels, net)\n",
    "        \n",
    "        if new_accuracy < accuracy_before:\n",
    "            print(\"Direzione sbagliata\")\n",
    "            for k, param in enumerate(net.parameters()):\n",
    "                param.data.add_(inverse[k])\n",
    "        \n",
    "            new_accuracy = test_minibatch(inputs, labels, net)\n",
    "            \n",
    "        accuracy_before = new_accuracy\n",
    "        \n",
    "        print(new_accuracy)\n",
    "        del inputs, labels\n",
    "        \n",
    "def full_train_SA(trainloader, model, gpu=True):\n",
    "    model.train()\n",
    "    \n",
    "    if i\n",
    "        accuracy_before = ut.test_train(trainloader, net)\n",
    "    print(\"Accuracy inizio epoca:\", accuracy_before)\n",
    "    \n",
    "    grad = None\n",
    "    inverse = []\n",
    "    \n",
    "    for param in net.parameters():\n",
    "        size = param.data.size()\n",
    "        grad = param.data.clone()\n",
    "        \n",
    "        #print(param.data)\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                grad.data[i][j] = rm.uniform(-1, 1) * maximum_percentage * param.data[i][j]\n",
    "        \n",
    "        inverse.append(grad.data.mul(-2))\n",
    "        param.data.add_(grad.data)\n",
    "\n",
    "    new_accuracy = ut.test_train(train_loader, net)\n",
    "\n",
    "    if new_accuracy[1] < accuracy_before[1]:\n",
    "        print(\"Direzione sbagliata infatti:\", new_accuracy[1])\n",
    "        for k, param in enumerate(net.parameters()):\n",
    "            param.data.add_(inverse[k])\n",
    "\n",
    "        new_accuracy = ut.test_train(train_loader, net)\n",
    "        \n",
    "    accuracy_before = new_accuracy\n",
    "\n",
    "    print(\"Accuracy fine epoca: \", new_accuracy)\n",
    "    \n",
    "    \n",
    "for epoch in range(1000):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    full_train_SA(train_loader, net, 1)\n",
    "    print(\"Validation test:\", ut.test(test_loader, net))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
